<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="description" content="Medical Hallucination Detection: A Comprehensive Benchmark for Detecting Hallucinations in Medical LLM Outputs.">
  <meta property="og:title" content="Medical Hallucination Detection" />
  <meta property="og:description" content="A comprehensive benchmark for detecting hallucinated outputs in medical language models." />
  <meta property="og:url" content="https://MedHallu.github.io/" />
  <meta name="twitter:title" content="Medical Hallucination Detection">
  <meta name="twitter:description" content="A comprehensive benchmark for detecting hallucinated outputs in medical LLMs.">
  <meta name="twitter:image" content="static/images/twitter_banner.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="medical, hallucination, detection, LLM, benchmark, research">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <title>Medical Hallucination Detection</title>
  
  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <!-- Bulma CSS -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <!-- Custom CSS -->
  <link rel="stylesheet" href="static/css/index.css">
  <!-- Font Awesome for icons -->
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
</head>

<body>

<!-- Hero Section (light background) -->
<section class="hero is-light">
  <div class="hero-body">
    <div class="container has-text-centered">
      <h1 class="title">Medical Hallucination Detection</h1>
      <h2 class="subtitle">A Comprehensive Benchmark for Detecting Hallucinations in Medical LLM Outputs</h2>
      
      <!-- Author List -->
      <p class="is-size-5">
        <strong>
          <a href="https://sites.google.com/view/shrey-pandit/home">Shrey Pandit</a><sup>1</sup>
        </strong>, 
        <strong>
          <a href="https://jiaweixu98.github.io/">Jiawei Xu</a><sup>1</sup>
        </strong>, 
        <strong>
          <a href="https://jyhong.gitlab.io/">Junyuan Hong</a><sup>1</sup>
        </strong>, 
        <strong>
          <a href="https://vita-group.github.io/research.html">Zhangyang Wang</a><sup>1</sup>
        </strong>, 
        <strong>
          <a href="https://tianlong-chen.github.io/">Tianlong Chen</a><sup>2</sup>
        </strong>, 
        <strong>
          <a href="https://kaidixu.com/">Kaidi Xu</a><sup>3</sup>
        </strong>, 
        <strong>
          <a href="https://yingding.ischool.utexas.edu/">Ying Ding</a><sup>1</sup>
        </strong>
      </p>
      <p class="is-size-6">
        <sup>1</sup>University of Texas at Austin | 
        <sup>2</sup>UNC Chapel Hill | 
        <sup>3</sup>Drexel University
      </p>

      <!-- Links Section -->
      <div class="column has-text-centered" style="margin-top: 1.5rem;">
        <div class="publication-links">
          <!-- Paper Link (Add URL if available) -->
          <span class="link-block">
            <a href="https://arxiv.org/abs/2502.14302" class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="ai ai-arxiv"></i>
              </span>
              <span>Paper</span>
            </a>
          </span>
          <!-- Code Link -->
          <span class="link-block">
            <a href="https://github.com/MedHallu" class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fab fa-github"></i>
              </span>
              <span>Code</span>
            </a>
          </span>
          <!-- Dataset Link -->
          <span class="link-block">
            <a href="https://huggingface.co/datasets/UTAustin-AIHealth/MedHallu" class="external-link button is-normal is-rounded is-dark">
              <span class="icon">ü§ó</span>
              <span>Dataset</span>
            </a>
          </span>
        </div>
      </div>

      <!-- First Image with controlled width -->
      <div class="columns is-centered" style="margin-top: 2rem;">
        <div class="column" style="max-width:600px; margin:0 auto;">
          <figure class="image" style="width:100%; margin:auto;">
            <img src="static/images/image1.png" alt="Overview Image" style="width:100%; height:auto;">
          </figure>
        </div>
      </div>

    </div>
  </div>
</section>

<!-- Abstract Section (white background) -->
<section class="section has-text-centered is-white">
  <div class="container">
    <h2 class="title is-3">Abstract</h2>
    <div class="content">
      <p>
        Advancements in Large Language Models (LLMs) and their increasing use in medical 
        question-answering necessitate rigorous evaluation of their reliability. A critical 
        challenge lies in hallucination, where models generate plausible yet factually incorrect 
        outputs. In the medical domain, this poses serious risks to patient safety and clinical 
        decision-making. To address this, we introduce <strong>MedHallu</strong>, the first 
        benchmark specifically designed for medical hallucination detection. MedHallu comprises 
        10,000 high-quality question-answer pairs derived from PubMedQA, with hallucinated answers 
        systematically generated through a controlled pipeline. Our experiments show that 
        state-of-the-art LLMs, including GPT-4o, Llama-3.1, and the medically fine-tuned UltraMedical, 
        struggle with this binary hallucination detection task, with the best model achieving an 
        F1 score as low as 0.625 for detecting ‚Äúhard‚Äù category hallucinations. Using bidirectional 
        entailment clustering, we show that harder-to-detect hallucinations are semantically closer 
        to ground truth. Through experiments, we also show incorporating domain-specific knowledge 
        and introducing a ‚Äúnot sure‚Äù category as one of the answer categories improves the precision 
        and F1 scores by up to 38% relative to baselines.
      </p>
    </div>
  </div>
</section>

<!-- Introduction Section (grey background) -->
<section class="section has-text-centered is-light">
  <div class="container">
    <h2 class="title is-3">Introduction</h2>
    <div class="content">
      <p>
        We present the <strong>Med</strong>ical <strong>Hallu</strong>cination detection dataset 
        (<strong>MedHallu</strong>), a comprehensive corpus of 10,000 medical question-answer pairs 
        derived from the established PubMedQA dataset. Each pair is meticulously annotated to 
        distinguish accurate responses from hallucinated content. Furthermore, MedHallu is stratified 
        into easy, medium, and hard detection tiers based on the subtlety of hallucinations, enabling 
        granular evaluation of model capabilities.
      </p>
    </div>

    <!-- Second Image (Placeholder or actual) -->
    <div class="columns is-centered" style="margin-top: 2rem;">
      <div class="column is-half">
        <figure class="image is-3by2">
          <img src="static/images/image2.png" alt="Pipeline">
        </figure>
      </div>
    </div>

  </div>
</section>

<!-- Methodology Section (white background) -->
<section class="section has-text-centered is-white">
  <div class="container">
    <h2 class="title is-3">Methodology</h2>
    <div class="content">
      <p>
        The proposed methodological framework comprises a three-phase pipeline architected for robust 
        hallucinated sample generation. The pipeline follows a sequential approach: 
        (1) stochastic sampling of potential hallucinated responses based on in-context examples and 
        precise definitions, 
        (2) LLM-based quality filtering mechanisms, 
        (3) correctness checking using bidirectional entailment and LLM prompting, and 
        (4) sequential improvement via TextGrad. 
        Inspired by HaluEval, we finally select the most similar sample generated‚Äîbased on semantic 
        similarity‚Äîif no high-quality sample is identified. This multi-layered approach enables 
        comprehensive identification and evaluation of linguistic hallucinations while minimizing 
        false positives.
      </p>
    </div>
  </div>
</section>

<!-- Results Section (grey background) -->
<section class="section has-text-centered is-light">
  <div class="container">
    <h2 class="title is-3">Results</h2>
    <div class="content">
      <p>
        Below is a comprehensive table comparing the performance of various LLMs with and without
        knowledge on the MedHallu dataset (10,000 samples).
      </p>
      <!-- Multi-column table with knowledge/no knowledge comparison -->
      <div class="table-container" style="overflow-x:auto; margin-top: 2rem;">
        <table class="table is-bordered is-striped is-hoverable is-fullwidth">
          <thead>
            <tr>
              <th rowspan="2" style="vertical-align: middle;">Model</th>
              <th colspan="5">Without Knowledge</th>
              <th colspan="5">With Knowledge</th>
              <th rowspan="2" style="vertical-align: middle;">Œî Knowledge</th>
            </tr>
            <tr>
              <th>Overall F1</th>
              <th>Overall P</th>
              <th>Easy F1</th>
              <th>Med F1</th>
              <th>Hard F1</th>
              <th>Overall F1</th>
              <th>Overall P</th>
              <th>Easy F1</th>
              <th>Med F1</th>
              <th>Hard F1</th>
            </tr>
          </thead>
          <tbody>
  <!-- General LLMs -->
  <tr>
    <td>GPT-4o<sup>*</sup></td>
    <td>0.737</td>
    <td>0.723</td>
    <td>0.844</td>
    <td>0.758</td>
    <td>0.625</td>
    <td>0.877</td>
    <td>0.882</td>
    <td>0.947</td>
    <td>0.880</td>
    <td>0.811</td>
    <td>0.140</td>
  </tr>
  <tr>
    <td>GPT-4o mini</td>
    <td>0.607</td>
    <td>0.772</td>
    <td>0.783</td>
    <td>0.603</td>
    <td>0.446</td>
    <td>0.841</td>
    <td>0.820</td>
    <td>0.914</td>
    <td>0.854</td>
    <td>0.761</td>
    <td>0.234</td>
  </tr>
  <tr>
    <td>Qwen2.5-14B-Instruct</td>
    <td>0.619</td>
    <td>0.691</td>
    <td>0.773</td>
    <td>0.611</td>
    <td>0.483</td>
    <td>0.852</td>
    <td>0.857</td>
    <td>0.935</td>
    <td>0.856</td>
    <td>0.769</td>
    <td>0.233</td>
  </tr>
  <tr>
    <td>Gemma-2-9b-Instruct</td>
    <td>0.515</td>
    <td>0.740</td>
    <td>0.693</td>
    <td>0.512</td>
    <td>0.347</td>
    <td>0.838</td>
    <td>0.809</td>
    <td>0.918</td>
    <td>0.848</td>
    <td>0.758</td>
    <td><strong>0.323</strong></td>
  </tr>
  <tr>
    <td>Llama-3.1-8B-Instruct</td>
    <td>0.522</td>
    <td><strong>0.791</strong></td>
    <td>0.679</td>
    <td>0.515</td>
    <td>0.372</td>
    <td>0.797</td>
    <td>0.775</td>
    <td>0.880</td>
    <td>0.796</td>
    <td>0.722</td>
    <td>0.275</td>
  </tr>
  <tr>
    <td>DeepSeek-R1-Distill-Llama-8B</td>
    <td>0.514</td>
    <td>0.570</td>
    <td>0.589</td>
    <td>0.515</td>
    <td>0.444</td>
    <td>0.812</td>
    <td>0.864</td>
    <td>0.895</td>
    <td>0.794</td>
    <td>0.751</td>
    <td>0.298</td>
  </tr>
  <tr>
    <td>Qwen2.5-7B-Instruct</td>
    <td>0.553</td>
    <td>0.745</td>
    <td>0.733</td>
    <td>0.528</td>
    <td>0.402</td>
    <td>0.839</td>
    <td>0.866</td>
    <td>0.923</td>
    <td>0.832</td>
    <td>0.770</td>
    <td>0.286</td>
  </tr>
  <tr>
    <td>Qwen2.5-3B-Instruct</td>
    <td>0.606</td>
    <td>0.495</td>
    <td>0.667</td>
    <td>0.602</td>
    <td>0.556</td>
    <td>0.676</td>
    <td>0.514</td>
    <td>0.693</td>
    <td>0.677</td>
    <td>0.661</td>
    <td>0.070</td>
  </tr>
  <tr>
    <td>Llama-3.2-3B-Instruct</td>
    <td>0.499</td>
    <td>0.696</td>
    <td>0.651</td>
    <td>0.467</td>
    <td>0.384</td>
    <td>0.734</td>
    <td>0.775</td>
    <td>0.822</td>
    <td>0.723</td>
    <td>0.664</td>
    <td>0.235</td>
  </tr>
  <tr>
    <td>Gemma-2-2b-Instruct</td>
    <td>0.553</td>
    <td>0.620</td>
    <td>0.680</td>
    <td>0.524</td>
    <td>0.457</td>
    <td>0.715</td>
    <td>0.786</td>
    <td>0.812</td>
    <td>0.705</td>
    <td>0.631</td>
    <td>0.162</td>
  </tr>
  <!-- Average (General LLMs, w/o GPT-4o) -->
  <tr>
    <td><strong>Average (General LLMs, w/o GPT-4o)</strong></td>
    <td><strong>0.533</strong></td>
    <td><strong>0.686</strong></td>
    <td><strong>0.674</strong></td>
    <td><strong>0.517</strong></td>
    <td>0.412</td>
    <td><strong>0.784</strong></td>
    <td><strong>0.789</strong></td>
    <td><strong>0.864</strong></td>
    <td><strong>0.781</strong></td>
    <td><strong>0.716</strong></td>
    <td><strong>0.251</strong></td>
  </tr>

  <!-- Medical Fine-Tuned LLMs -->
  <tr>
    <td>OpenBioLLM-Llama3-8B</td>
    <td>0.484</td>
    <td>0.490</td>
    <td>0.494</td>
    <td>0.474</td>
    <td>0.483</td>
    <td>0.424</td>
    <td>0.567</td>
    <td>0.438</td>
    <td>0.412</td>
    <td>0.423</td>
    <td>-0.060</td>
  </tr>
  <tr>
    <td>BioMistral-7B</td>
    <td>0.570</td>
    <td>0.518</td>
    <td>0.627</td>
    <td>0.563</td>
    <td><strong>0.525</strong></td>
    <td>0.648</td>
    <td>0.516</td>
    <td>0.652</td>
    <td>0.660</td>
    <td>0.634</td>
    <td>0.078</td>
  </tr>
  <tr>
    <td>Llama-3.1-8B-UltraMedical</td>
    <td><strong>0.619</strong></td>
    <td>0.657</td>
    <td><strong>0.747</strong></td>
    <td><strong>0.596</strong></td>
    <td>0.524</td>
    <td>0.773</td>
    <td>0.679</td>
    <td>0.832</td>
    <td>0.777</td>
    <td><strong>0.718</strong></td>
    <td>0.153</td>
  </tr>
  <tr>
    <td>Llama3-Med42-8B</td>
    <td>0.416</td>
    <td><strong>0.829</strong></td>
    <td>0.600</td>
    <td>0.379</td>
    <td>0.264</td>
    <td><strong>0.797</strong></td>
    <td><strong>0.856</strong></td>
    <td><strong>0.898</strong></td>
    <td><strong>0.794</strong></td>
    <td>0.707</td>
    <td><strong>0.381</strong></td>
  </tr>
  <tr>
    <td><strong>Average (Medical Fine-Tuned LLMs)</strong></td>
    <td>0.522</td>
    <td>0.623</td>
    <td>0.617</td>
    <td>0.503</td>
    <td><strong>0.449</strong></td>
    <td>0.660</td>
    <td>0.654</td>
    <td>0.705</td>
    <td>0.660</td>
    <td>0.620</td>
    <td>0.138</td>
  </tr>
</tbody>

        </table>
      </div>
      <p style="margin-top: 1rem; font-size: 0.9em;">
        ‚ÄúOverall P‚Äù denotes precision. ‚ÄúŒî Knowledge‚Äù is the performance change in Overall F1
        when knowledge is provided. 
      </p>
    </div>
  </div>
</section>

<!-- Conclusion Section (white background) -->
<section class="section has-text-centered is-white">
  <div class="container">
    <h2 class="title is-3">Conclusion</h2>
    <div class="content">
      <p>
        We introduce MedHallu, a comprehensive benchmark comprising 10,000 rigorously 
        curated medical question-answer pairs with hallucinated answers. MedHallu 
        integrates fine-grained categorization of medical hallucination types, a 
        hallucination generation framework that balances difficulty levels while 
        mitigating single-LLM bias through multi-model majority voting, and 
        systematically evaluates diverse LLM configurations‚Äô hallucination detection 
        capabilities.
      </p>
      <p>
        Our evaluation reveals that existing LLMs exhibit significant limitations in 
        detecting medical hallucinations, particularly struggling with ‚Äúhard‚Äù 
        hallucination answers, which are closer in distance to the ground truth. We 
        also provide insights into enhancing LLMs‚Äô hallucination detection: when 
        knowledge is provided, general-purpose LLMs can outperform medical fine-tuned 
        models, and allowing models to decline to answer by providing a ‚Äúnot sure‚Äù 
        option improves precision in critical applications.
      </p>
      <p>
        As the largest open medical hallucination benchmark to date, MedHallu serves 
        as a valuable resource for evaluating LLMs‚Äô medical hallucination detection 
        abilities and offers insights into the cautious use of LLMs in high-stakes 
        medical domains.
      </p>
    </div>
  </div>
</section>

<!-- Footer Section (white background) -->
<section class="section is-white">
  <div class="container has-text-centered">
    <p>
      <small>&copy; 2025 MedHallu Project. All rights reserved. | 
        <a href="">Contact</a>
      </small>
    </p>
  </div>
</section>

<!-- BibTeX Citation Section -->
<section class="section has-text-centered is-white">
  <div class="container">
    <h2 class="title is-3">BibTeX Citation</h2>
    <div class="content has-text-left" style="max-width: 800px; margin: 0 auto;">
      <pre><code>@misc{pandit2025medhallucomprehensivebenchmarkdetecting,
  title={MedHallu: A Comprehensive Benchmark for Detecting Medical Hallucinations in Large Language Models}, 
  author={Shrey Pandit and Jiawei Xu and Junyuan Hong and Zhangyang Wang and Tianlong Chen and Kaidi Xu and Ying Ding},
  year={2025},
  eprint={2502.14302},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2502.14302},
}</code></pre>
    </div>
  </div>
</section>


<!-- JS (jQuery, custom scripts if any) -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script src="static/js/index.js"></script>
</body>
</html>
